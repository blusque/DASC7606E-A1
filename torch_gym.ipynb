{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Exercise: Introduction to Basic Deep Learning Architecture in PyTorch\n",
    "\n",
    "In this exercise, we will explore the fundamentals of deep learning by building a basic neural network using PyTorch. PyTorch is a popular deep learning framework that provides a flexible and efficient platform for building and training neural networks.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Understand the basic concepts of deep learning and neural networks.\n",
    "- Learn how to set up and use PyTorch for building neural networks.\n",
    "- Implement a simple feedforward neural network.\n",
    "- Train the neural network on a sample dataset.\n",
    "- Evaluate the performance of the trained model.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting this exercise, you should have a basic understanding of:\n",
    "\n",
    "- Python programming\n",
    "- Linear algebra and calculus\n",
    "- Machine learning concepts\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. **Data Preparation**: Load and preprocess the dataset.\n",
    "2. **Model Definition**: Define the architecture of the neural network.\n",
    "3. **Loss Function and Optimizer**: Specify the loss function and the optimizer.\n",
    "4. **Training the Model**: Train the neural network on the training data.\n",
    "5. **Evaluation**: Evaluate the model's performance on the test data.\n",
    "\n",
    "By the end of this exercise, you will have a solid understanding of how to build and train a basic neural network using PyTorch. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "!pip install -q torch torchvision matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation\n",
    "\n",
    "In our this small exercise, we will use [Fashion-MNIST](https://arxiv.org/abs/1708.07747) as the example dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Download and load the Fashion-MNIST dataset through torchvision.datasets\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root='./data/FashionMNIST', train=True, download=True, transform=transforms.ToTensor()) # Training dataset\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='./data/FashionMNIST', train=False, download=True, transform=transforms.ToTensor()) # Testing dataset\n",
    "\n",
    "# Take a look at the dataset\n",
    "print(type(mnist_train))\n",
    "print(len(mnist_train), len(mnist_test))\n",
    "\n",
    "feature, label = mnist_train[0]\n",
    "print(feature.shape, label) # Channel, Height, Width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 10 categories in the Fashion-MNIST dataset, which are:\n",
    "# 0: T-shirt/top 1: Trouser 2: Pullover 3: Dress 4: Coat 5: Sandal 6: Shirt 7: Sneaker 8: Bag 9: Ankle boot\n",
    "# Define a function to transform the label index into the corresponding text label\n",
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "\n",
    "# Define a function to visualize the Fashion-MNIST dataset\n",
    "def show_fashion_mnist(images, labels):\n",
    "\n",
    "    # Configure the display properties\n",
    "    from IPython import display\n",
    "    display.set_matplotlib_formats('svg')\n",
    "\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((28, 28)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "# Display first 10 samples in training dataset\n",
    "X, y = [], []\n",
    "for i in range(10):\n",
    "    X.append(mnist_train[i][0])\n",
    "    y.append(mnist_train[i][1])\n",
    "show_fashion_mnist(X, get_fashion_mnist_labels(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# TODO: Finish the function to return the dataloader for training\n",
    "#       and testing dataset according to the example above\n",
    "###################### YOUR CODE HERE ############################\n",
    "def load_data_fashion_mnist(batch_size, resize = None, root = \"./data/FashionMNIST\"):\n",
    "    trans = []\n",
    "    # Add any needed transformations\n",
    "    ### START CODE HERE ###\n",
    "    trans.append(\"?\")\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = \"?\"\n",
    "    test_iter = \"?\"\n",
    "    return train_iter, test_iter\n",
    "\n",
    "##################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model definition\n",
    "\n",
    "In this section, we are going to build classification models to be trained on Fashion-MNIST, which are as follows.\n",
    "\n",
    "- Multilayer Perceptron (28x28, 256, 10)\n",
    "- CNN ([LeNet](https://ieeexplore.ieee.org/document/726791))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Multiple layers perceptron\n",
    "\n",
    "# Define the model parameters size\n",
    "num_inputs, num_outputs, num_hiddens = 28*28, 10, 256\n",
    "\n",
    "# Firstly, define the FlattenLayer, which is used to flatten the input tensor\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        ##################################################################\n",
    "        # TODO: Finish the forward function to flatten the input tensor\n",
    "        ###################### YOUR CODE HERE ############################ \n",
    "        pass\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "\n",
    "# Define the multiple layers perceptron model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens):\n",
    "        super(MLP, self).__init__()\n",
    "        ##################################################################\n",
    "        # TODO: Finish the __init__ function to define the model structure\n",
    "        ###################### YOUR CODE HERE ############################\n",
    "        flatten_layer = FlattenLayer()\n",
    "        self.net = nn.Sequential(\n",
    "            flatten_layer,\n",
    "            \"?\",\n",
    "            nn.ReLU(),\n",
    "            \"?\",\n",
    "        )\n",
    "        ##################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ##################################################################\n",
    "        # TODO: Finish the forward function to define the forward pass\n",
    "        ###################### YOUR CODE HERE ############################\n",
    "        pass\n",
    "\n",
    "        ##################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CNN (LeNet)\n",
    "\n",
    "# Define the LeNet model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        ##################################################################\n",
    "        # TODO: Finish the __init__ function to define the model structure\n",
    "        ###################### YOUR CODE HERE ############################\n",
    "        # Convolutional layer\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, \"?\", \"?\"), # in_channels, out_channels, kernel_size\n",
    "            \"?\",                    # activation function\n",
    "            nn.MaxPool2d(\"?\", \"?\"), # kernel_size, stride\n",
    "            \"?\",                    # another Conv2d layer\n",
    "            \"?\",                    # activation function\n",
    "            \"?\",                    # another MaxPool2d layer\n",
    "        )\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(\n",
    "            \"?\",\n",
    "            \"?\",\n",
    "            \"?\",\n",
    "        )\n",
    "        ##################################################################\n",
    "\n",
    "    def forward(self, img):\n",
    "        ##################################################################\n",
    "        # TODO: Finish the forward function to define the forward pass\n",
    "        ###################### YOUR CODE HERE ############################\n",
    "        pass\n",
    "\n",
    "        ##################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loss function and optimizer\n",
    "\n",
    "After we define the model, we need to determine loss function and optimizer for next step training.\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "  - Cross Entropy Loss\n",
    "\n",
    "#### Optimizer\n",
    "\n",
    "  - SGD\n",
    "  - AdaGrad\n",
    "  - RMSProp\n",
    "  - Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Loss function and optimization\n",
    "\n",
    "# Since we can directly use the built-in loss function and\n",
    "# optimization function in PyTorch, we don't need to define them here.\n",
    "# Just call api.\n",
    "\n",
    "net = LeNet() # or net = MLP(num_inputs, num_outputs, num_hiddens)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5) # or optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training\n",
    "\n",
    "Every component for training a classification model is ready. The core part in the project is the training script.\n",
    "\n",
    "Try to compose them up and kick off the training process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training script\n",
    "\n",
    "def train(net, train_iter, test_iter, criterion, device, num_epochs, optimizer):\n",
    "    # Send model to device\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(num_epochs):\n",
    "        # Initialize variables\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        # Iterate through the training dataset\n",
    "        for X, y in train_iter:\n",
    "            # Send data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_hat = net(X)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute gradient\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update variables\n",
    "            train_l_sum += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "\n",
    "            # Update number of samples\n",
    "            n += y.shape[0]\n",
    "\n",
    "        # Compute test accuracy\n",
    "        test_acc = evaluate_accuracy(test_iter, device, net)\n",
    "        print(f'epoch {epoch + 1}, loss {train_l_sum / n:.4f}, train acc {train_acc_sum / n:.3f}, '\n",
    "              f'test acc {test_acc:.3f}, time {time.time() - start:.1f} sec')\n",
    "\n",
    "def evaluate_accuracy(data_iter, device, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            # Send data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "##################################################################\n",
    "# TODO: Set the parameters and call the train function\n",
    "###################### YOUR CODE HERE ############################\n",
    "num_epochs = \"?\"\n",
    "batch_size = \"?\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
    "train(net, train_iter, test_iter, criterion, device, num_epochs, optimizer)\n",
    "##################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation on Test Set\n",
    "\n",
    "After training the model, the next step is to evaluate its performance on the test set. This will help us understand how well the model generalizes to unseen data. \n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "- Use the trained model to make predictions on the test set.\n",
    "- Calculate the accuracy of the model on the test set.\n",
    "- Visualize some of the test set predictions to get a qualitative sense of the model's performance.\n",
    "\n",
    "By the end of this section, we will have a clear understanding of the model's performance on the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Evaluation on Test Set\n",
    "\n",
    "def evaluate_model(net, test_iter, device):\n",
    "    net = net.to(device)\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "    test_acc = evaluate_accuracy(test_iter, net)\n",
    "    print(f'Test accuracy: {test_acc:.3f}')\n",
    "\n",
    "    # Visualize some predictions\n",
    "    X, y = next(iter(test_iter))\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    y_hat = net(X).argmax(dim=1)\n",
    "    X, y, y_hat = X.cpu(), y.cpu(), y_hat.cpu()\n",
    "\n",
    "    # Display the first 10 images and their predicted labels\n",
    "    show_fashion_mnist(X[:10], get_fashion_mnist_labels(y_hat[:10]))\n",
    "    print('True labels:', get_fashion_mnist_labels(y[:10]))\n",
    "    print('Predicted labels:', get_fashion_mnist_labels(y_hat[:10]))\n",
    "\n",
    "##################################################################\n",
    "# TODO: Set the parameters and call the evaluate_model function\n",
    "###################### YOUR CODE HERE ############################\n",
    "device = \"?\"\n",
    "evaluate_model(net, test_iter, device)\n",
    "##################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
